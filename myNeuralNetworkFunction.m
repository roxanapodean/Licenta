function [y1] = myNeuralNetworkFunction(x1)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Auto-generated by MATLAB, 24-Apr-2024 19:51:33.
% 
% [y1] = myNeuralNetworkFunction(x1) takes these arguments:
%   x = 6xQ matrix, input #1
% and returns:
%   y = 1xQ matrix, output #1
% where Q is the number of samples.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.keep = [1 6];
x1_step2.xoffset = [0.278;0];
x1_step2.gain = [0.0501844277720623;0.00796874756019362];
x1_step2.ymin = -1;

% Layer 1
b1 = [-1.3342647301812990968;-3.1488663476331111291;0.0011684037776011268681;1.89819769150928086;1.5010133485309036239];
IW1_1 = [2.9982278942208293593 -3.6853650252532781373;2.6994769848772333098 -0.2879030745222840304;-9.5887772831975315313 0.58155827611774046915;2.5883209075809361366 2.403315084116232736;-0.23116323303974750658 4.1256462379548528574];

% Layer 2
b2 = 0.55810004008388358621;
LW2_1 = [-2.9904243984376623899 0.5192891978572247158 10.611805017699474263 -2.1996092213063169751 0.90831706700444281299];

% ===== SIMULATION ========

% Dimensions
Q = size(x1,2); % samples

% Input 1
xp1 = removeconstantrows_apply(x1,x1_step1);
xp1 = mapminmax_apply(xp1,x1_step2);

% Layer 1
a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*xp1);

% Layer 2
a2 = logsig_apply(repmat(b2,1,Q) + LW2_1*a1);

% Output 1
y1 = a2;
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
  y = bsxfun(@minus,x,settings.xoffset);
  y = bsxfun(@times,y,settings.gain);
  y = bsxfun(@plus,y,settings.ymin);
end

% Remove Constants Input Processing Function
function y = removeconstantrows_apply(x,settings)
  y = x(settings.keep,:);
end

% Sigmoid Positive Transfer Function
function a = logsig_apply(n,~)
  a = 1 ./ (1 + exp(-n));
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
  a = 2 ./ (1 + exp(-2*n)) - 1;
end
